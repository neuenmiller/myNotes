\chapter{Determinants}
\section{3 by 3 Determinants and Cofactors}

\begin{enumerate}
    \item \(\det \) of \(A= \begin{bmatrix}
        a & b  \\
        c & d  \\
    \end{bmatrix}\) 
    is \(ad - bc\), the singular matrix \(\begin{bmatrix}
        a & 2a  \\
        c & 2c  \\
    \end{bmatrix}\) 
    has \(\det  = 0\)
    \item \(P A = \begin{bmatrix}
        0 & 1  \\
        1 & 0  \\
    \end{bmatrix}
    \begin{bmatrix}
        a & b  \\
        c & d  \\
    \end{bmatrix}
    = 
    \begin{bmatrix}
        c & d  \\
        a & b  \\
    \end{bmatrix}\)  
    has \(\det  P A = bc - ad = - \det A\)  
    \item \(\det \) of \(\begin{bmatrix}
        xa + yA & xb + yB  \\
        c & d  \\
    \end{bmatrix}\) 
    is \(x(ad - bc) + y(Ad - Bc)\), where the \(\det \)  is linear in row 1 by itself. 
    \item \(3 \times 3\)  determinants have \(3! = 6\)terms. 
\end{enumerate}

One thing to remember that determinants reverse sign when two rows are exchanged \((\det A \rightarrow -\det A)\) 

For \(2 \times 2\) matrices, \(\det = 0\) means that \(\frac{a}{c} = \frac{b}{d}\), meaning the columns are parallel. For \(n \times n\), it means that the columns of \(A\) are not independent. 

\subsection{3 by 3 Determinants}

\(3 \times 3\) matrices have 6 terms, starting from \(\det I = 1\). 

\[
\begin{bmatrix}
1 &   &   \\
  & 1 &   \\
  &   & 1
\end{bmatrix}
%
\begin{bmatrix}
  & 1 &   \\
1 &   &   \\
  &   & 1
\end{bmatrix}
%
\begin{bmatrix}
  & 1 &   \\
  &   & 1 \\
1 &   &
\end{bmatrix}
%
\begin{bmatrix}
  &   & 1 \\
  & 1 &   \\
1 &   &
\end{bmatrix}
%
\begin{bmatrix}
  &   & 1 \\
1 &   &   \\
  & 1 &
\end{bmatrix}
%
\begin{bmatrix}
1 &   &   \\
  &   & 1 \\
  & 1 &
\end{bmatrix}
\]

The \(\det \)  are respectively \(+1, -1, +1, -1, +1, -1\). Which means row exchanges multiplies \(\det \) by \(-1\). 

Say we make a matrix of \(\begin{bmatrix}
    a & b & c  \\
    p & q & r  \\
    x & y & z  \\
\end{bmatrix}\) 

It would be 

\[
\begin{bmatrix}
a & & \\
& q & \\
& & z
\end{bmatrix}
%
\begin{bmatrix}
& b & \\
p & & \\
& & z
\end{bmatrix}
%
\begin{bmatrix}
& b & \\
& & r \\
x & &
\end{bmatrix}
%
\begin{bmatrix}
& & c \\
& q & \\
x & &
\end{bmatrix}
%
\begin{bmatrix}
& & c \\
p & & \\
& y &
\end{bmatrix}
%
\begin{bmatrix}
a & & \\
& & r \\
& y &
\end{bmatrix}
\]

We can see that the determinant of \(A\) is linear in each row separately. We can combine them to get \(\det A = aqz + brx + cpy - ary - bpz- cqx\). 

Notice that each term have at least one entry from the row and column. That means that a \(4 \times 4\) matrix will have 24 definitions. 

\[
    A_3 = 
    \begin{bmatrix}
        2 & -1 & 0  \\
        -1 & 2 & -1  \\
        0 & -1 & 2  \\
    \end{bmatrix}
    \text{ \(\det\) = 4 }
\]
\(2 \times 2 \times 2\) already give us \(8\). We'll see how the rest goes. 

\[
\begin{bmatrix}
2 &   &    \\
  &   & -1 \\
  & -1 &
\end{bmatrix}
%
\begin{bmatrix}
  & -1 &   \\
-1 &    &   \\
  &    & 2
\end{bmatrix}
%
\begin{bmatrix}
  & -1 &    \\
  &    & -1 \\
0 &    &
\end{bmatrix}
%
\begin{bmatrix}
  &    & 0  \\
-1 &    &    \\
  & -1 &
\end{bmatrix}
%
\begin{bmatrix}
  &   & 0 \\
  & 2 &   \\
0 &   &
\end{bmatrix}
\]

So, \(8 -2 -2 = 4\). Since we get one number from every row and every column, if any entire row or column are zero, then the whole term is zero. 

\[
A_4=
\begin{bmatrix}
2 & -1 & 0 & 0\\
-1 & 2 & -1 & 0\\
0 & -1 & 2 & -1\\
0 & 0 & -1 & 2
\end{bmatrix},
\qquad
\det A_4
= 2 \det\!\begin{bmatrix}
2 & -1 & 0\\
-1 & 2 & -1\\
0 & -1 & 2
\end{bmatrix}
- (-1)\det\!\begin{bmatrix}
-1 & -1 & 0\\
0 & 2 & -1\\
0 & -1 & 2
\end{bmatrix}.
\]


We can see also see that \(A_4\) is made from smaller matrixes, namely \(A_3\) or \(A_{n-1} \) for general cases. We simply exclude the column and row it is in.  

Now might wonder why the second matrix has a \(-1\)? That is because it's cofactor is  \(a_{12} \)! We can find out what is minus or not by doing \((-1)^{i \times j}\). Here, \(i \times j\) is odd, so the \(-1\) goes through.    


\[
\begin{bmatrix}
+ & - & + & -\\
- & + & - & +\\
+ & - & + & -\\
- & + & - & +
\end{bmatrix}
\]


What does this means?
\[
  \det \begin{bmatrix}
    a & b  \\
    c & d  \\
  \end{bmatrix}
  = \det  
  \begin{bmatrix}
    a &   \\
     & d  \\
  \end{bmatrix}
  + 
  \det  
  \begin{bmatrix}
     & b  \\
    c &   \\
  \end{bmatrix}
  = a \times d \text{\textbf{ MINUS } } b \times c
\]

\subsection{Cofactors and a formula for \(A^{-1} \) }

Cofactor formula of \(3 \times 3\) matrix is simply 
\[
  \det  A = a (qz - ry) + b (rx - pz) + c(py - qx)
\] 
Notice that each cofactor is \(2 \times 2\). Also notice that \(b\) has a cofactor of \(rx - pz\) instead of \(pz - rx\). Why? \(b\) is \(M_{12} \) and \(1 + 2\) is odd. 

\begin{enumerate}
  \item For \(i, j\) in \(C_ij\), remove \(i\) row and \(j\) column from A. 
  \item \(C_{ij}\) equals \(-1^{i+j}\) times the \(\det \) of the remaining minor 
  \item The cofactor formula along row \(i\) is \(\det  A = a_{i1}C_{i1} + \ldots + a_{in}C_{in}    \)  
\end{enumerate}

The cofactor \(C_{ij} \) just collects all term in \(\det A\) that are multiplied by \(a_{ij} \)

\[
  A = 
  \begin{bmatrix}
    a & b  \\
    c & d  \\
  \end{bmatrix}
  , C = 
  \begin{bmatrix}
    d & -c  \\
    -b & a  \\
  \end{bmatrix}
\]

Now, if \(A \times C^T\), we get \(\det A \times I\). 
\[
  AC^T = 
  \begin{bmatrix}
    ad-bc & 0  \\
    0 &  ad-bc \\
  \end{bmatrix}
  = 
  \begin{bmatrix}
    \det A &  0 \\
    0 & \det A  \\
  \end{bmatrix}
  = (\det A) I
\]  
Which gives us:
\[
  \text{Inverse matrix formula }
  \quad 
  A^{-1} = \frac{C^T}{\det A} 
\]

\subsection{Example: The \(-1, 2, -1\) tridiagonal matrix}

Remember, \(D_n = \det A_n = 2 \det(A_{n-1}) + (-1) (1)^{i+j} (M_{12} )\)

\[
\det\!\begin{bmatrix}
2 & -1 & 0 & 0 & \cdots & 0\\
-1 & 2 & -1 & 0 & \cdots & 0\\
0 & -1 & 2 & -1 & \ddots & \vdots\\
0 & 0 & -1 & 2 & \ddots & 0\\
\vdots & \vdots & \ddots & \ddots & \ddots & -1\\
0 & 0 & \cdots & 0 & -1 & 2
\end{bmatrix}
=
2(-1)^{1+1}\!
\det\!\begin{bmatrix}
2 & -1 & 0 & \cdots & 0\\
-1 & 2 & -1 & \ddots & \vdots\\
0 & -1 & 2 & \ddots & 0\\
\vdots & \ddots & \ddots & \ddots & -1\\
0 & \cdots & 0 & -1 & 2
\end{bmatrix}
\;-\;
1\,(-1)^{1+2}\!
\det\!\begin{bmatrix}
-1 & -1 & 0 & \cdots & 0\\
0 & 2 & -1 & \ddots & \vdots\\
0 & -1 & 2 & \ddots & 0\\
\vdots & \ddots & \ddots & \ddots & -1\\
0 & \cdots & 0 & -1 & 2
\end{bmatrix}.
\]


The first one is plain old \(n - 1\), but the second one, remember that it is \(M_{12} \). And the cofactor is \((-1)^{1+2} = -1\). 
\[
  \det  A_n = 2 \det A_{n-1} - \det A_{n-2}  
\]   

Working it, we find that \(A_n = 2, 3, 4, 5\) for \(n = 1, 2, 3, 4\). We now see that \(\det A_n = n + 1\) for every \(n\). Cofactor formula is most useful when the matrix is mostly zero, so we have few cofactor to find.         

\section{Computing and Using Determinants}

\begin{enumerate}
  \item \(\det A^T = \det A, \det AB = (\det A)(\det B), \vert \det Q \vert = 1 \).
  \item Elimination matrix have \(\det E = 1\) therefore \(\det EA = \det A\).  
  \item Cramer's rule find \(x = A^{-1} b \) from ratio of determinant, slow. 
  \item \(\det A = \pm \) product of the pivots in \(A = LU\), fast. 
  \item Big formula for \(\det A\) has \(n!\) term from \(n!\) permutation, very slow.      
\end{enumerate}

Determinant of a square matrix tells us that invertible matrix has \(\det A \neq 0\), where a singular matrix can have \(\det A = 0\). 

\[
\det\!\begin{bmatrix}
a & b & c\\
0 & q & r\\
0 & 0 & z
\end{bmatrix}
=
\det\!\begin{bmatrix}
a & 0 & 0\\
0 & q & 0\\
0 & 0 & z
\end{bmatrix}
= aqz.
\]

It tells us a few things. 

\begin{enumerate}
  \item \(\det A^T = \det A\)
  \item \(\det (AB) = (\det A)(\det B)\)  
  \item Orthogonal matrices \(Q\) have determinant \(\pm 1\).  
\end{enumerate}

The last one requires a bit more explanation. 
\[
  Q^T Q = I, (\det Q)^2 = (\det Q^T)(\det Q) = 1, \text{ therefore } Q = \pm 1. 
\]

\emph{Invertible matrices have \(\det A = \pm\) product of the pivots. }

If \(A = LU\), \(\det A = (\det L)(\det U) = \det U\). 
If \(PA = LU\), then there was row exchanges/permutation and \(P = \pm 1\).     

\subsection{Proving the Properties}

We must agree on 3 things.
\begin{enumerate}
  \item \(\det I = 1\) 
  \item Exchanging two rows of \(A\) turns \(\det A \rightarrow - \det A\)
  \item If row 1 of \(A\) is a combination \(cv + dw\) then add 2 determinants.     
\end{enumerate}

\[
\det\begin{bmatrix}
c\,v + d\,w\\
\text{row }2\\
\vdots\\
\text{row }n
\end{bmatrix}
= c\,\det\!\begin{bmatrix}
v\\
\text{row }2\\
\vdots\\
\text{row }n
\end{bmatrix}
+ d\,\det\!\begin{bmatrix}
w\\
\text{row }2\\
\vdots\\
\text{row }n
\end{bmatrix}.
\]

\(\det A\) is linear with respect to every row separately. If \(A\) has two equal rows, its determinant is \textbf{zero}. If you try to swap two rows, that mean it swaps sign, but if it has to swap sign and stay the same, that means it's 0. Rule 3 means that subtracting \(d\) times row \(i\) from row \(j\) leaves \(\det A\) unchanged. 

\[
\det\!\begin{bmatrix}
\text{row }1\\
\text{row }2 - d\,\text{row }1\\
\vdots\\
\text{row }n
\end{bmatrix}
=
\det\!\begin{bmatrix}
\text{row }1\\
\text{row }2\\
\vdots\\
\text{row }n
\end{bmatrix}
-
d\,\det\!\begin{bmatrix}
\text{row }1\\
\text{row }1\\
\vdots\\
\text{row }n
\end{bmatrix}
= \det A.
\]

This is linearity in row 2 with row 1 fixed.  It means elimination steps from the original matrix \(A\) to an upper triangular \(U\) do not change the determinant. Elimination is the way to simplify \(A\) and its determinant. 

\[
  \det A = \det U = U_{11} U_{22} U_{33}  \ldots U_{nn} 
\]   

\subsection{Cramer's Rule to Solve \(Ax = b\) }

Cramer's rule work by letting \(M_1\) has determinant \(x_1\). If you multiply it by \(A\), the first column becomes \(Ax\) which is \(b\). 

\[
A
\begin{bmatrix}
x_1 & 0 & 0\\
x_2 & 1 & 0\\
x_3 & 0 & 1
\end{bmatrix}
=
\begin{bmatrix}
b_1 & a_{12} & a_{13}\\
b_2 & a_{22} & a_{23}\\
b_3 & a_{32} & a_{33}
\end{bmatrix}
= B_1.
\]

Which gives us the product rule:
\[
  (\det A)(x_1) = \det B_1 \text{ or }
  x_1 = \frac{\det B_1}{\det A}
\]

\[
\begin{bmatrix} a_1 & a_2 & a_3 \end{bmatrix}
\begin{bmatrix}
1 & x_1 & 0\\
0 & x_2 & 0\\
0 & x_3 & 1
\end{bmatrix}
=
\begin{bmatrix} a_1 & b & a_3 \end{bmatrix}
= B_2.
\]

Same thing but \((\det A)(x_2) = \det B_2\) or \(x_2 = \frac{\det B_2}{\det A}\)  

\textbf{Example 1:} Solve for \(3x_1 + 4x_2 = 2, 5x_1 + 6x_2 = 4\)

\[
  \det A = 
  \begin{bmatrix}
    3 & 4  \\
    5 & 6  \\
  \end{bmatrix}
  \quad 
  \det B_1 = 
  \begin{bmatrix}
    2 & 4  \\
    4 & 6  \\
  \end{bmatrix}
  \quad 
  \det B_2 = 
  \begin{bmatrix}
    3 & 2  \\
    5 & 4  \\
  \end{bmatrix}
\]

Determinant of \(B_1\) and \(B_2\) are \(-4\) and \(2\), divided by \(\det A = -2\)



\[
  x_1 = \frac{-4}{-2} = 2
  \quad 
  x_2 = \frac{2}{-2} = -1
  \quad 
  \text{Check }
  \begin{bmatrix}
    3 & 4  \\
    5 & 6  \\
  \end{bmatrix}
  \begin{bmatrix}
     2 \\
     -1 \\
  \end{bmatrix}
  = 
  \begin{bmatrix}
     2 \\
     4 \\
  \end{bmatrix}
\]


And so the Cramer's rule is:
\[
  x_1 = \frac{\det B_1}{\det A}
  \quad 
  x_2 = \frac{\det B_2}{\det A}
  \quad 
  \ldots 
  \quad 
  x_n = \frac{\det B_n}{\det A}
\]



\textbf{Example 2:} We want to find a \(A[x \quad y] = I\). 
\[
  Ax = 
  \begin{bmatrix}
    a & b  \\
    c & d  \\
  \end{bmatrix}
  \begin{bmatrix}
     x_1 \\
     x_2 \\
  \end{bmatrix}
  = 
  \begin{bmatrix}
     1 \\
     0 \\
  \end{bmatrix}
  \quad 
  Ay = 
  \begin{bmatrix}
    a & b  \\
    c & d  \\
  \end{bmatrix}
  \begin{bmatrix}
     y_1 \\
     y_2 \\
  \end{bmatrix}
  = 
  \begin{bmatrix}
     0 \\
     1 \\
  \end{bmatrix}
\]



We will need four determinant for \(x_1, x_2, y_1, y_2\)



Giving us the determinants: \(d, -c, -b, a\). 


\[
  x_1 = \frac{d}{\vert A \vert },
  \quad 
  x_2 = \frac{-c}{\vert A \vert },
  \quad 
  x_3 = \frac{-b}{\vert A \vert }
  \quad 
  x_4 = \frac{a}{\vert A \vert }
  \text{ and }
  A^{-1} = \frac{1}{ad - bc}
  \begin{bmatrix}
    d & -b  \\
    -c & a  \\
  \end{bmatrix} 
\]

\(A^{-1} \) involves the cofactor of \(A\), and the determinant in each \(B_j\) in Cramer's rule is a cofactor of \(A\). 

\[
\det\!\begin{bmatrix}
1 & a_{12} & a_{13}\\
0 & a_{22} & a_{23}\\
0 & a_{32} & a_{33}
\end{bmatrix}\quad
\det\!\begin{bmatrix}
a_{11} & 1 & a_{13}\\
a_{21} & 0 & a_{23}\\
a_{31} & 0 & a_{33}
\end{bmatrix}\quad
\det\!\begin{bmatrix}
a_{11} & a_{12} & 1\\
a_{21} & a_{22} & 0\\
a_{31} & a_{32} & 0
\end{bmatrix}
\]

\[
  C_{ij} = B_j 
\]

\(B_1\) is the cofactor \(C_{11} = a_{22}a_{33} - a_{23}a_{32}\), \(\det B_2 = -(a_{21}a_{33} - a_{23}a_{31})\). Notice how \(C_{12} \) go into column 1 of \(A^{-1} \)? 
\[
  (A^{-1} )_{ij} = \frac{C_{ji} }{\det A} 
  \quad 
  A^{-1} = \frac{C^T}{\det A} 
\]     

\subsection{The Big Formula for the Determinant: \(n!\) term }





\section{Areas and Volumes by Determinants}
